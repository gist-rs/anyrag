# Configuration for a local AI provider (e.g., Ollama, LM Studio)
embedding:
  api_url: "${EMBEDDINGS_API_URL}"
  model_name: "text-embedding-qwen3-embedding-8b"

providers:
  local_default:
    provider: "local"
    api_url: "${AI_API_URL}"
    api_key: null
    model_name: "gemma-2-9b-it-mlx"

tasks:
  query_generation:
    provider: "local_default"
    system_prompt: |
      You are a SQL expert for the specified database. Write a readonly SQL query
      that answers the user's question. Expected output is a single SQL query only.
    user_prompt: |
      Follow these rules to create production-grade SQL:

      1. For questions about "who", "what", or "list", use DISTINCT to avoid duplicate results.
      2. When filtering, always explicitly exclude NULL values (e.g., `your_column IS NOT NULL`).
      3. For questions about "today", you MUST use one of the formats provided in the # TODAY context. Choose the format that matches the data in the relevant date column. If the column is TEXT, you may need to use string matching (e.g., `your_column LIKE 'YYYY-MM-DD%'`).
      4. For searches involving a person's name, use a `LIKE` clause for partial matching (e.g., `name_column LIKE 'John%'`).
      5. If a Japanese name includes an honorific like "さん", remove the honorific before using the name in the query.
      6. For keyword searches (e.g., 'Rust'), it is vital to search across multiple fields. Your `WHERE` clause must use `LIKE` and `OR` to check for the keyword in all plausible text columns based on the schema. For example, you should check fields like `subject_name`, `class_name`, and `memo`.
      7. **Crucially, do not format data in the query** (e.g., using `TO_CHAR` or `FORMAT`). Return raw numbers and dates. Formatting is handled separately.

      Use the provided table schema to ensure the query is correct. Do not use placeholders for table or column names.

      # Context
      {context}

      # User question
      {prompt}

  rag_synthesis:
    provider: "local_default"
    system_prompt: |
      You are a strict, factual AI. Your sole purpose is to answer the user's
      question based *only* on the provided #Context.
    user_prompt: |
      # User Question
      {prompt}
      # Context
      {context}
      # Your Answer:

  knowledge_distillation:
    provider: "local_default"
    system_prompt: |
      You are an expert data extraction and reconciliation agent...
    user_prompt: |
      # Markdown Content to Process:
      {markdown_content}

  query_analysis:
    provider: "local_default"
    system_prompt: |
      You are an expert query analyst. Your task is to extract key **Entities**
      and **Keyphrases** from the user's query...
    user_prompt: |
      # USER QUERY:
      {prompt}

  llm_rerank:
    provider: "local_default"
    system_prompt: |
      You are an expert search result re-ranker...
    user_prompt: |
      # User Query:
      {query_text}
      # Articles to Re-rank:
      {articles_context}
