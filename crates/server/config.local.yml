# Configuration for a local AI provider (e.g., Ollama, LM Studio)
embedding:
  api_url: "${EMBEDDINGS_API_URL}"
  model_name: "text-embedding-qwen3-embedding-8b"

providers:
  local_default:
    provider: "local"
    api_url: "${AI_API_URL}"
    api_key: null
    model_name: "gemma-2-9b-it-mlx"

# Override all default tasks to use the local provider.
# The prompts for these tasks are inherited from `config.prompt.yml`
# unless you create a `prompt.yml` file to override them.
tasks:
  query_generation:
    provider: "local_default"
  direct_generation:
    provider: "local_default"
  rag_synthesis:
    provider: "local_default"
  knowledge_distillation:
    provider: "local_default"
  query_analysis:
    provider: "local_default"
  llm_rerank:
    provider: "local_default"
  knowledge_augmentation:
    provider: "local_default"
  knowledge_metadata_extraction:
    provider: "local_default"
