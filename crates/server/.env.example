# -----------------------------------------------------------------------------
# Required Environment Variables
# -----------------------------------------------------------------------------
# Copy this file to .env and fill in your actual values.

# Your API key for the selected AI Provider (e.g., Google Gemini).
# This is a secret and should not be committed to version control.
AI_API_KEY=your_api_key_here

# The ID of your Google Cloud project. This is now used only for running
# the BigQuery-specific example, not for the main server startup.
BIGQUERY_PROJECT_ID=your-gcp-project-id



# The full URL for the AI provider's API endpoint.
# IMPORTANT: Do NOT wrap the URL in quotes.
AI_API_URL=https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent

# -----------------------------------------------------------------------------
# Optional Core Configuration
# -----------------------------------------------------------------------------
# These variables have sensible defaults but can be uncommented and changed.

# The AI provider to use. Can be "gemini" or "local". Defaults to "gemini".
# AI_PROVIDER=gemini

# For the "local" provider, you can specify a model name.
# AI_MODEL=your_local_model_name

# The port for the server to listen on inside the container. Defaults to 9090.
# PORT=9090

# Sets the logging level. Valid levels: trace, debug, info, warn, error
# RUST_LOG=info

# -----------------------------------------------------------------------------
# Prompt Customization (Optional)
# -----------------------------------------------------------------------------
# These variables allow you to set server-wide default prompts, which is useful
# for customizing the AI's behavior without changing the code. These can still
# be overridden by individual API requests if needed.

# --- 1. Query Generation: System Prompt ---
# Controls the AI's core instructions for generating queries.
# Use this to change its persona, add strict rules, or adapt to a new query language.
# Example: Make the AI always use lowercase for comparisons.
# QUERY_SYSTEM_PROMPT_TEMPLATE="You are a SQL expert for BigQuery. You must use `LOWER()` on all string comparisons."

# --- 2. Query Generation: User Prompt ---
# Controls how the user's question and table context are presented to the AI for query generation.
# Available placeholders: {language}, {context}, {prompt}, {alias_instruction}
# Example: A simpler template.
# QUERY_USER_PROMPT_TEMPLATE="Context: {context}. Question: {prompt}. Generate a {language} query."

# --- 3. Response Formatting: System Prompt ---
# Controls the AI's persona for the final response formatting step.
# This does not affect query generation.
# Example: Make the AI always respond excitedly.
# FORMAT_SYSTEM_PROMPT_TEMPLATE="You are a helpful assistant who is very excited! Always start your response with 'Wow!'"

# --- 4. Response Formatting: User Prompt ---
# Controls how the data and original question are presented to the AI for formatting.
# Available placeholders: {prompt}, {instruction}, {content}
# Example: A template focused on summarization.
# FORMAT_USER_PROMPT_TEMPLATE="Based on the original question '{prompt}', please summarize the following data: {content}"
