# Plan: Fix Ingestion Parsing Logic

## 1. Goal

The primary goal is to fix the data ingestion pipeline to ensure it correctly parses all Q&A pairs from the source HTML, making them available for retrieval.

## 2. Diagnosis

We have successfully confirmed that the core RAG (Retrieval-Augmented Generation) pipeline—including hybrid search, re-ranking, and AI-driven answer synthesis—is functioning correctly.

This was proven by:
1.  Manually inserting a specific, problematic Q&A document directly into the database within the `knowledge_prompt2` example.
2.  Running the example, which then successfully retrieved the correct document and generated the expected answer.

This result isolates the problem to the initial **data ingestion and parsing stage**. The current logic in `fetch_web_content` fails to correctly identify and extract the specific Q&A pair ("*หลักเกณฑ์การออมต่อเป็นอย่างไร*") from the source URL, which is why it was never retrieved in the original test.

## 3. Implementation Plan

The focus is now entirely on improving the HTML parsing and content extraction logic in the `anyrag` library.

### 3.1. Add Debug Logging to the Parser

To understand why the parser is failing, we need to see what it sees.

**File to Modify**: `anyrag/crates/lib/src/ingest/knowledge.rs`

**Changes**:
1.  Inside the `fetch_web_content` function, add `tracing::debug!` statements to log:
    *   The raw HTML content received from the URL (`html_raw`).
    *   The HTML content *after* the aggressive tag cleaning (`html`).
    *   The final Markdown content generated by the `scraper` logic or the `htmd` fallback (`content_builder`).
    This will reveal exactly where the desired content is being lost.

### 3.2. Refine HTML Parsing Logic

Based on the debugging output, the parsing logic will be adjusted.

**File to Modify**: `anyrag/crates/lib/src/ingest/knowledge.rs`

**Changes**:
1.  **Analyze the Logs**: Examine the logged HTML to see the structure around the missing Q&A pair. The current `scraper` logic, which looks for text nodes starting with `Q :` and `A :`, might be too simplistic if the HTML structure is inconsistent.
2.  **Adjust Selectors/Logic**: If the structure is different, adjust the `scraper` selectors or the text processing logic to correctly capture the question and answer. We may need a more flexible approach that accounts for variations in whitespace or surrounding tags.
3.  **Improve Fallback**: If the `scraper` logic is still insufficient, we may need to improve the initial cleaning process before handing the HTML over to the `htmd` fallback converter.

## 4. Verification

The fix will be verified by running the original, unmodified `knowledge_prompt2` example.

`RUST_LOG=info,anyrag::ingest=debug cargo run -p anyrag-server --example knowledge_prompt2`

The expected outcome is:
1.  The debug logs will show that the target Q&A pair is successfully extracted into Markdown.
2.  The full example will run successfully, and the final answer to the question "*มีเงิน 2 หมื่นออมต่อได้มั้ย*" will be the correct, fact-based response derived from the ingested content.